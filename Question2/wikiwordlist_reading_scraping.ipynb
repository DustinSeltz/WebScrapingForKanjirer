{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of Creator\n",
    "CREATOR_NAME = \"Jingheng Wang\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is intended to scrape the readings/meanings of the whole 20K word list from [Jisho](jisho.org). A .py file with temporary saving features should be in the same directory with this notebook. That .py file has the same usage but friendlier if you want to run the program on a server. It really takes **A LONG PERIOD OF TIME** to scrape the whole word list! According to my calculation, in total more than 40K requests are made before the program terminates.\n",
    "\n",
    "Run all the cells (or the .py file) will generate a \"wikiword_table_new.csv\" file, containing all word/reading/meaning entries of the 20K word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wikitionary_wordlist.csv')\n",
    "sr = df['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamei_list = list(\"あいうえおかきくけこさしすせそたちつてとなにぬねのはひふへほまみむめもやゆよらりるれろわをんがぎぐげござじずぜぞだぢづでどばびぶべぼパピプペポアイウエロカキクケコサシスセソタチツテトナニヌネノハヒフヘホマミムメモヤユヨラリルレロワヲンガギグゲゴザジズゼゾダヂヅデドバビブベボパピプペポャュョー\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_furigana(soup):\n",
    "    furi = soup.find('span',class_='furigana')\n",
    "    #print(list(furi.children))\n",
    "    txt = furi.next_sibling.next_sibling\n",
    "    text_cont = list(str(txt.get_text()).strip())\n",
    "    furistring = \"\"\n",
    "    txtstring = \"\"\n",
    "    text_loc = 0\n",
    "    for f1 in furi.children:\n",
    "        #print(f1)\n",
    "        if ((f1 != '\\n') & (f1 is not None)):\n",
    "            t1 = text_cont[text_loc]\n",
    "            txtstring += t1\n",
    "            if (f1.get_text() == '') & (t1 in kamei_list):\n",
    "                furistring += t1\n",
    "            else:\n",
    "                furistring += f1.get_text().strip()\n",
    "            text_loc += 1\n",
    "    return (furistring, txtstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meanings(soup):\n",
    "    meanings = \"\"\n",
    "    raw_meanings = soup.findAll('div', class_='meaning-wrapper')\n",
    "    for x in raw_meanings:\n",
    "        flag = x.findAll('span', class_='meaning-definition-section_divider')\n",
    "        if ((flag is not None) & (flag != [])):\n",
    "            #print(flag)\n",
    "            tag = flag[0]\n",
    "            #print(tag)\n",
    "            #print(tag.next_sibling)\n",
    "            meanings += tag.get_text() + tag.next_sibling.get_text() + '$'\n",
    "    return meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests Made: 1, status 200\n",
      "三つ / みっつ / 1. three$\n",
      "Requests Made: 2, status 404\n"
     ]
    }
   ],
   "source": [
    "wordlist = []\n",
    "furigana = []\n",
    "meanings = []\n",
    "\n",
    "url_base = 'https://jisho.org/word/'\n",
    "\n",
    "requests = 0\n",
    "i = 0\n",
    "\n",
    "for k in np.arange(len(sr)):\n",
    "    i = 0\n",
    "    word = sr[k]\n",
    "#word = '三つ'\n",
    "if (True):\n",
    "    while (True):\n",
    "        if (i == 0):\n",
    "            url = url_base+word\n",
    "        else:\n",
    "            url = url_base+word+'-'+str(i)\n",
    "            \n",
    "        #print(url)\n",
    "        \n",
    "        response = get(url)\n",
    "        requests += 1\n",
    "        print(\"Requests Made: {}, status {}\".format(requests, response.status_code))\n",
    "        sleep(2)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if (response.status_code != 200):\n",
    "            if (response.status_code == 408):\n",
    "                # Timed Out\n",
    "                i -= 1\n",
    "                continue\n",
    "            if (response.status_code != 404):\n",
    "                print(\"Error: code {} at word {}, i={}\".format(response.status_code, word, i-1))\n",
    "            break\n",
    "        else:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            furi, txt = get_furigana(soup)\n",
    "            mean = get_meanings(soup)\n",
    "            print(txt+' / '+furi+' / '+mean)\n",
    "            wordlist.append(txt)\n",
    "            furigana.append(furi)\n",
    "            meanings.append(mean)\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "        'word': wordlist,\n",
    "        'reading': furigana,\n",
    "        'meaning': meanings\n",
    "        }).to_csv('wikiword_table_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
